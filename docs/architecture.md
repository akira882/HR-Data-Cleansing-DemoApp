# 技術仕様書 (Architectural Deep Dive)

本システムは、大規模な人事データ（数百〜数千レコード以上）を安全かつ迅速に処理し、経営意思決定に直結するインサイトを生成するために、以下の設計原則に基づき構築されています。

## 1. 疎結合なモジュール設計 (Modular Design)
`src/` ディレクトリ内の各モジュールは、特定の責任（クリーニング、検証、計算）に特化しており、互いに独立して動作・テストが可能です。

- **DataCleaner (`data_cleaning.py`)**: データの正規化を担当。他のロジックが変更されても、クリーニングのルールを独立して更新可能。
- **DataValidator (`validation.py`)**: 「ビジネスルール」に基づいた論理チェック。将来的な「給与上限の変更」などにも設定変更のみで対応できるよう設計。
- **KPICalculator (`kpi_calculator.py`)**: 統計処理をカプセル化。記述統計から推測統計への拡張を考慮。

## 2. 冪等性の確保 (Idempotency)
クリーニング処理や計算処理は、同じデータに対して何度実行しても同じ結果を返すように設計されています。これにより、データパイプラインの途中でエラーが発生しても、最初から安全にリトライが可能です。

## 3. セキュリティと環境分離
- **APIキーの秘匿**: `.env` ファイルによる管理を徹底し、コード内に機密情報が混入することを防止。
- **Immutable Data**: `data/raw/` 以下のデータは読み取り専用として扱い、加工後のデータは `data/processed/` に分離して出力することで、データのトレーサビリティを確保。

## 4. AI エージェントの統合 (LLM Integration)
単なるキーワードマッチングではなく、Anthropic Claude 3.5 Sonnet を採用することで、以下の「統計的文脈の理解」を実現しています。

- **相関関係の推察**: 「若手層の離職率が高く、かつ給与が平均より低い」といった複数の要因から、AIが「報酬体系のミスマッチ」という仮説を生成。
- **非構造化データの構造化**: 異常値のリストをビジネスニュース形式の要約へと変換。

---
*設計に関する詳細は、コード内の Google Style Docstrings を参照してください。*
